{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Billboard Segmentation Model Training\n",
    "\n",
    "This notebook:\n",
    "1. Uploads your clean billboard dataset (1200 CLIP-filtered images)\n",
    "2. Uses SAM to convert bbox annotations → segmentation polygon masks\n",
    "3. Trains YOLOv8-seg for instance segmentation\n",
    "4. Downloads the trained model\n",
    "\n",
    "**Make sure to select GPU runtime:** Runtime → Change runtime type → T4 GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Check GPU & Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import torch\nprint(f\"GPU available: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\nelse:\n    print(\"No GPU! Go to Runtime -> Change runtime type -> T4 GPU\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "!pip install -q git+https://github.com/facebookresearch/segment-anything.git ultralytics opencv-python-headless\nfrom segment_anything import sam_model_registry\nprint(\"All packages installed!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Step 2: Get Dataset from GitHub"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import zipfile\nimport os\n\n# Download dataset from GitHub release\n!wget -q \"https://github.com/fxsBulqit/billboard-segmentation/releases/download/v1.0-dataset/clean_dataset.zip\"\n\n# Extract\nwith zipfile.ZipFile('clean_dataset.zip', 'r') as z:\n    z.extractall('.')\n\n# Verify\nn_images = len(os.listdir('clean_dataset/images'))\nn_labels = len(os.listdir('clean_dataset/labels'))\nprint(f\"Extracted: {n_images} images, {n_labels} labels\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Download SAM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth -O sam_vit_b.pth\n",
    "print(f\"SAM model downloaded: {os.path.getsize('sam_vit_b.pth') / 1e6:.0f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Generate Segmentation Masks with SAM\n",
    "\n",
    "This takes each image + its YOLO bbox, feeds the bbox to SAM as a prompt, and gets back a precise segmentation mask. The mask is then converted to a polygon in YOLO segmentation format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from segment_anything import sam_model_registry, SamPredictor\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Load SAM\n",
    "print(\"Loading SAM...\")\n",
    "sam = sam_model_registry[\"vit_b\"](checkpoint=\"sam_vit_b.pth\")\n",
    "sam.to(\"cuda\")\n",
    "predictor = SamPredictor(sam)\n",
    "print(\"SAM loaded on GPU!\")\n",
    "\n",
    "IMAGES_DIR = Path(\"clean_dataset/images\")\n",
    "BBOX_LABELS_DIR = Path(\"clean_dataset/labels\")\n",
    "SEG_LABELS_DIR = Path(\"clean_dataset/seg_labels\")\n",
    "SEG_LABELS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "\n",
    "def bbox_yolo_to_xyxy(yolo_bbox, img_w, img_h):\n",
    "    cx, cy, bw, bh = yolo_bbox\n",
    "    x1 = int((cx - bw / 2) * img_w)\n",
    "    y1 = int((cy - bh / 2) * img_h)\n",
    "    x2 = int((cx + bw / 2) * img_w)\n",
    "    y2 = int((cy + bh / 2) * img_h)\n",
    "    return [max(0, x1), max(0, y1), min(img_w, x2), min(img_h, y2)]\n",
    "\n",
    "\n",
    "def mask_to_polygon(mask, epsilon_factor=0.005):\n",
    "    h, w = mask.shape\n",
    "    contours, _ = cv2.findContours(\n",
    "        mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE\n",
    "    )\n",
    "    if not contours:\n",
    "        return None\n",
    "\n",
    "    contour = max(contours, key=cv2.contourArea)\n",
    "    perimeter = cv2.arcLength(contour, True)\n",
    "    epsilon = epsilon_factor * perimeter\n",
    "    simplified = cv2.approxPolyDP(contour, epsilon, True)\n",
    "\n",
    "    if len(simplified) < 4:\n",
    "        return None\n",
    "\n",
    "    points = simplified.reshape(-1, 2).astype(float)\n",
    "    points[:, 0] /= w\n",
    "    points[:, 1] /= h\n",
    "    return np.clip(points, 0.0, 1.0)\n",
    "\n",
    "\n",
    "# Process all images\n",
    "images = sorted(IMAGES_DIR.glob(\"*.jpg\"))\n",
    "success = 0\n",
    "failed = 0\n",
    "total_masks = 0\n",
    "\n",
    "for img_path in tqdm(images, desc=\"Generating masks\"):\n",
    "    label_path = BBOX_LABELS_DIR / img_path.name.replace('.jpg', '.txt')\n",
    "    if not label_path.exists():\n",
    "        failed += 1\n",
    "        continue\n",
    "\n",
    "    image = cv2.imread(str(img_path))\n",
    "    if image is None:\n",
    "        failed += 1\n",
    "        continue\n",
    "\n",
    "    img_h, img_w = image.shape[:2]\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    predictor.set_image(image_rgb)\n",
    "\n",
    "    with open(label_path) as f:\n",
    "        lines = f.read().strip().split('\\n')\n",
    "\n",
    "    seg_lines = []\n",
    "    for line in lines:\n",
    "        parts = line.strip().split()\n",
    "        if len(parts) < 5:\n",
    "            continue\n",
    "\n",
    "        class_id = parts[0]\n",
    "        yolo_bbox = [float(x) for x in parts[1:5]]\n",
    "        x1, y1, x2, y2 = bbox_yolo_to_xyxy(yolo_bbox, img_w, img_h)\n",
    "\n",
    "        input_box = np.array([x1, y1, x2, y2])\n",
    "        masks, scores, _ = predictor.predict(\n",
    "            box=input_box, multimask_output=True\n",
    "        )\n",
    "\n",
    "        best_idx = scores.argmax()\n",
    "        mask = masks[best_idx]\n",
    "        polygon = mask_to_polygon(mask)\n",
    "\n",
    "        if polygon is None:\n",
    "            # Fallback to rectangle from bbox\n",
    "            cx, cy, bw, bh = yolo_bbox\n",
    "            polygon = np.array([\n",
    "                [cx - bw/2, cy - bh/2],\n",
    "                [cx + bw/2, cy - bh/2],\n",
    "                [cx + bw/2, cy + bh/2],\n",
    "                [cx - bw/2, cy + bh/2],\n",
    "            ])\n",
    "\n",
    "        points_str = \" \".join(f\"{p[0]:.6f} {p[1]:.6f}\" for p in polygon)\n",
    "        seg_lines.append(f\"{class_id} {points_str}\")\n",
    "        total_masks += 1\n",
    "\n",
    "    if seg_lines:\n",
    "        seg_path = SEG_LABELS_DIR / img_path.name.replace('.jpg', '.txt')\n",
    "        with open(seg_path, 'w') as f:\n",
    "            f.write('\\n'.join(seg_lines) + '\\n')\n",
    "        success += 1\n",
    "    else:\n",
    "        failed += 1\n",
    "\n",
    "print(f\"\\nDone! {success} images, {total_masks} masks generated, {failed} failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Visualize Some SAM Masks\n",
    "\n",
    "Let's check that SAM did a good job before training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import random\n",
    "\n",
    "def show_mask_result(img_name):\n",
    "    img = cv2.imread(str(IMAGES_DIR / img_name))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    h, w = img.shape[:2]\n",
    "\n",
    "    seg_path = SEG_LABELS_DIR / img_name.replace('.jpg', '.txt')\n",
    "    if not seg_path.exists():\n",
    "        print(f\"No seg label for {img_name}\")\n",
    "        return\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "    ax.imshow(img)\n",
    "\n",
    "    with open(seg_path) as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            coords = [float(x) for x in parts[1:]]\n",
    "            points = [(coords[i] * w, coords[i+1] * h) for i in range(0, len(coords), 2)]\n",
    "\n",
    "            polygon = patches.Polygon(\n",
    "                points, closed=True, fill=True,\n",
    "                facecolor='lime', edgecolor='red',\n",
    "                alpha=0.3, linewidth=2\n",
    "            )\n",
    "            ax.add_patch(polygon)\n",
    "\n",
    "    ax.set_title(img_name)\n",
    "    ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Show 6 random examples\n",
    "all_seg = [f.name.replace('.txt', '.jpg') for f in sorted(SEG_LABELS_DIR.glob('*.txt'))]\n",
    "samples = random.sample(all_seg, min(6, len(all_seg)))\n",
    "for s in samples:\n",
    "    show_mask_result(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Prepare Dataset for YOLOv8-seg Training\n",
    "\n",
    "Split into train/val/test and create data.yaml."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import random\n",
    "\n",
    "TRAIN_DIR = Path(\"billboard_seg_dataset\")\n",
    "\n",
    "# Clean up if exists\n",
    "if TRAIN_DIR.exists():\n",
    "    shutil.rmtree(TRAIN_DIR)\n",
    "\n",
    "for split in ['train', 'val', 'test']:\n",
    "    (TRAIN_DIR / split / 'images').mkdir(parents=True)\n",
    "    (TRAIN_DIR / split / 'labels').mkdir(parents=True)\n",
    "\n",
    "# Get all images that have seg labels\n",
    "seg_files = sorted(SEG_LABELS_DIR.glob('*.txt'))\n",
    "all_names = [f.stem for f in seg_files]\n",
    "\n",
    "random.seed(42)\n",
    "random.shuffle(all_names)\n",
    "\n",
    "# 80/15/5 split\n",
    "n = len(all_names)\n",
    "train_names = all_names[:int(0.80 * n)]\n",
    "val_names = all_names[int(0.80 * n):int(0.95 * n)]\n",
    "test_names = all_names[int(0.95 * n):]\n",
    "\n",
    "def copy_files(names, split):\n",
    "    for name in names:\n",
    "        # Image\n",
    "        src_img = IMAGES_DIR / f\"{name}.jpg\"\n",
    "        if src_img.exists():\n",
    "            shutil.copy2(src_img, TRAIN_DIR / split / 'images' / f\"{name}.jpg\")\n",
    "        # Seg label\n",
    "        src_lbl = SEG_LABELS_DIR / f\"{name}.txt\"\n",
    "        if src_lbl.exists():\n",
    "            shutil.copy2(src_lbl, TRAIN_DIR / split / 'labels' / f\"{name}.txt\")\n",
    "\n",
    "copy_files(train_names, 'train')\n",
    "copy_files(val_names, 'val')\n",
    "copy_files(test_names, 'test')\n",
    "\n",
    "print(f\"Train: {len(train_names)} images\")\n",
    "print(f\"Val:   {len(val_names)} images\")\n",
    "print(f\"Test:  {len(test_names)} images\")\n",
    "\n",
    "# Create data.yaml\n",
    "data_yaml = f\"\"\"path: /content/billboard_seg_dataset\n",
    "train: train/images\n",
    "val: val/images\n",
    "test: test/images\n",
    "\n",
    "nc: 1\n",
    "names: ['billboard']\n",
    "\"\"\"\n",
    "\n",
    "with open(TRAIN_DIR / 'data.yaml', 'w') as f:\n",
    "    f.write(data_yaml)\n",
    "\n",
    "print(f\"\\ndata.yaml written to {TRAIN_DIR / 'data.yaml'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Train YOLOv8-seg Model\n",
    "\n",
    "Training a segmentation model on the clean, SAM-annotated dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load YOLOv8 segmentation base model\n",
    "model = YOLO('yolov8m-seg.pt')  # medium model - good balance of speed/accuracy\n",
    "\n",
    "# Train\n",
    "results = model.train(\n",
    "    data='/content/billboard_seg_dataset/data.yaml',\n",
    "    epochs=100,\n",
    "    imgsz=640,\n",
    "    batch=16,\n",
    "    patience=15,         # early stopping if no improvement for 15 epochs\n",
    "    device=0,            # GPU\n",
    "    workers=2,\n",
    "    name='billboard_seg',\n",
    "    # Augmentation\n",
    "    hsv_h=0.015,\n",
    "    hsv_s=0.5,\n",
    "    hsv_v=0.3,\n",
    "    degrees=5.0,\n",
    "    translate=0.1,\n",
    "    scale=0.3,\n",
    "    flipud=0.0,          # no vertical flip (billboards don't flip upside down)\n",
    "    fliplr=0.5,\n",
    "    mosaic=0.8,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: View Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from pathlib import Path\n",
    "\n",
    "# Find the training run directory\n",
    "run_dir = sorted(Path('runs/segment').glob('billboard_seg*'))[-1]\n",
    "print(f\"Results in: {run_dir}\")\n",
    "\n",
    "# Show training curves\n",
    "if (run_dir / 'results.png').exists():\n",
    "    display(Image(filename=str(run_dir / 'results.png'), width=900))\n",
    "\n",
    "# Show validation predictions\n",
    "for img_name in ['val_batch0_pred.jpg', 'val_batch1_pred.jpg']:\n",
    "    img_path = run_dir / img_name\n",
    "    if img_path.exists():\n",
    "        print(f\"\\n{img_name}:\")\n",
    "        display(Image(filename=str(img_path), width=900))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Test on Sample Images\n",
    "\n",
    "Run the trained model on test images to see segmentation quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load best model\n",
    "best_model = YOLO(str(run_dir / 'weights' / 'best.pt'))\n",
    "\n",
    "# Get test images\n",
    "test_images = sorted(Path('billboard_seg_dataset/test/images').glob('*.jpg'))[:8]\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, img_path in enumerate(test_images):\n",
    "    results = best_model(str(img_path), verbose=False)\n",
    "    result = results[0]\n",
    "\n",
    "    # Plot with masks\n",
    "    annotated = result.plot()\n",
    "    annotated = cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    axes[idx].imshow(annotated)\n",
    "    axes[idx].set_title(img_path.name[:25], fontsize=9)\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.suptitle('Segmentation Results on Test Set', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Download Trained Model\n",
    "\n",
    "Download the best model weights to use locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import shutil\n",
    "\n",
    "best_weights = run_dir / 'weights' / 'best.pt'\n",
    "output_name = 'billboard_seg_best.pt'\n",
    "\n",
    "shutil.copy2(best_weights, output_name)\n",
    "print(f\"Model size: {os.path.getsize(output_name) / 1e6:.1f} MB\")\n",
    "\n",
    "# Also zip the full results\n",
    "shutil.make_archive('training_results', 'zip', str(run_dir))\n",
    "\n",
    "print(\"\\nDownloading model...\")\n",
    "files.download(output_name)\n",
    "\n",
    "print(\"\\nDownloading full training results...\")\n",
    "files.download('training_results.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Quick Replacement Test\n",
    "\n",
    "Test the new segmentation model does billboard replacement with actual polygon masks instead of bboxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def replace_billboard_seg(image_path, ad_path, model):\n",
    "    \"\"\"Replace billboards using segmentation masks.\"\"\"\n",
    "    img = cv2.imread(str(image_path))\n",
    "    ad = cv2.imread(str(ad_path))\n",
    "\n",
    "    results = model(str(image_path), verbose=False)\n",
    "    result = results[0]\n",
    "\n",
    "    if result.masks is None:\n",
    "        print(f\"No billboards found in {image_path}\")\n",
    "        return img\n",
    "\n",
    "    output = img.copy()\n",
    "\n",
    "    for i, mask in enumerate(result.masks.xy):\n",
    "        if len(mask) < 4:\n",
    "            continue\n",
    "\n",
    "        # Get the polygon points\n",
    "        pts = mask.astype(np.int32)\n",
    "\n",
    "        # Get bounding rect of the polygon for perspective transform\n",
    "        rect = cv2.boundingRect(pts)\n",
    "        x, y, w, h = rect\n",
    "\n",
    "        if w < 20 or h < 20:\n",
    "            continue\n",
    "\n",
    "        # Find the 4 corner-like points for perspective transform\n",
    "        # (top-left, top-right, bottom-right, bottom-left)\n",
    "        hull = cv2.convexHull(pts)\n",
    "        epsilon = 0.02 * cv2.arcLength(hull, True)\n",
    "        approx = cv2.approxPolyDP(hull, epsilon, True)\n",
    "\n",
    "        if len(approx) == 4:\n",
    "            # Perfect quad\n",
    "            corners = approx.reshape(4, 2).astype(np.float32)\n",
    "        else:\n",
    "            # Use bounding rect corners\n",
    "            corners = np.array([\n",
    "                [x, y], [x + w, y],\n",
    "                [x + w, y + h], [x, y + h]\n",
    "            ], dtype=np.float32)\n",
    "\n",
    "        # Sort corners: TL, TR, BR, BL\n",
    "        center = corners.mean(axis=0)\n",
    "        angles = np.arctan2(corners[:, 1] - center[1], corners[:, 0] - center[0])\n",
    "        order = np.argsort(angles)\n",
    "        sorted_corners = corners[order]\n",
    "        # Rearrange to TL, TR, BR, BL\n",
    "        tl_idx = np.argmin(sorted_corners[:, 0] + sorted_corners[:, 1])\n",
    "        sorted_corners = np.roll(sorted_corners, -tl_idx, axis=0)\n",
    "\n",
    "        # Resize ad to match\n",
    "        ad_h, ad_w = ad.shape[:2]\n",
    "        ad_corners = np.array([\n",
    "            [0, 0], [ad_w, 0],\n",
    "            [ad_w, ad_h], [0, ad_h]\n",
    "        ], dtype=np.float32)\n",
    "\n",
    "        # Perspective transform\n",
    "        M = cv2.getPerspectiveTransform(ad_corners, sorted_corners)\n",
    "        warped = cv2.warpPerspective(ad, M, (img.shape[1], img.shape[0]))\n",
    "\n",
    "        # Create mask from the actual segmentation polygon\n",
    "        seg_mask = np.zeros(img.shape[:2], dtype=np.uint8)\n",
    "        cv2.fillPoly(seg_mask, [pts], 255)\n",
    "\n",
    "        # Apply replacement only within the seg mask\n",
    "        output[seg_mask > 0] = warped[seg_mask > 0]\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "# Test on a few images (upload your ad image ss.png if you want)\n",
    "# For demo, just show the segmentation masks\n",
    "test_imgs = sorted(Path('billboard_seg_dataset/test/images').glob('*.jpg'))[:4]\n",
    "\n",
    "fig, axes = plt.subplots(1, len(test_imgs), figsize=(20, 5))\n",
    "for idx, img_path in enumerate(test_imgs):\n",
    "    results = best_model(str(img_path), verbose=False)\n",
    "    annotated = results[0].plot()\n",
    "    annotated = cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB)\n",
    "    axes[idx].imshow(annotated)\n",
    "    axes[idx].axis('off')\n",
    "    n_masks = len(results[0].masks.xy) if results[0].masks else 0\n",
    "    axes[idx].set_title(f\"{n_masks} billboard(s)\")\n",
    "\n",
    "plt.suptitle('Segmentation Model Output')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ]
}